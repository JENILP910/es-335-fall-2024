{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = \"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\"  # Do not share this key with anyone\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"gemma-9b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> 1. Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data. Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LAYING' 'SITTING' 'STANDING' 'WALKING' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_UPSTAIRS']\n",
      "**Prediction:**\n",
      "\n",
      "**1. LAYING:**\n",
      "- Low acceleration values along all axes.\n",
      "\n",
      "\n",
      "**2. SITTING:**\n",
      "- Moderate acceleration values along the x and y axes, low values along the z-axis.\n",
      "\n",
      "\n",
      "**3. STANDING:**\n",
      "- Moderate to high acceleration values along all axes.\n",
      "\n",
      "\n",
      "**4. WALKING:**\n",
      "- Moderate to high acceleration values along the x and y axes, high values along the z-axis.\n",
      "\n",
      "\n",
      "**5. WALKING_DOWNSTAIRS:**\n",
      "- High acceleration values along the z-axis, moderate values along the x and y axes.\n",
      "\n",
      "\n",
      "**6. WALKING_UPSTAIRS:**\n",
      "- High acceleration values along the z-axis, low to moderate values along the x and y axes.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_dataset = pd.read_csv(\"X_Train_Test_data.csv\")\n",
    "y_dataset = pd.read_csv(\"Y_train_test_data.csv\")\n",
    "\n",
    "X_array = np.array(X_dataset)\n",
    "X_array_reshape = X_array.copy().reshape(180, 500, 3)\n",
    "y_array = np.array(y_dataset[\"class_label\"])\n",
    "# print(X_array[1000][:])\n",
    "# print(X_array_reshape[2][0][:])\n",
    "activities = np.unique(y_dataset[\"activity_name\"])\n",
    "# print(activities)\n",
    "seed = 40\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array_reshape, y_array, test_size=0.3, random_state=seed, stratify=y_array)\n",
    "\n",
    "data = X_train\n",
    "# print(X_array_reshape)\n",
    "for i in range(1, 4):\n",
    "    query = f\"\"\"\n",
    "    You are a data analysis model!\n",
    "    \n",
    "    I have a dataset of accelerometer of shape (500, 3) readings that record activities like 'LAYING' 'SITTING' 'STANDING' 'WALKING' 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS'. \n",
    "    The data is structured as sequences of measurements in three dimensions: x, y, and z axes. Each sequence represents a different activity, though I don't have any data regarding which data represents what activity.\n",
    "    Based on this data, your task is to predict what activity each sequence is most likely representing: 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
    "    'WALKING_UPSTAIRS'? Please provide a brief reason for your prediction for each sequence.\n",
    "    These 500 reading have been taken over a period of 10sec on 50Hz frequency using accelerometer for one activity.\n",
    "\n",
    "    Data: {X_train[i]}\n",
    "    \"\"\" \n",
    "\n",
    "    # To use Groq LLMs \n",
    "    model_name = \"gemma-7b\" # We can choose any model from the groq_models dictionary\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "\n",
    "    print(answer.content)\n",
    "    print('*-'*100)\n",
    "\n",
    "# print(X_train.shape, X_test.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 6 6 4 4]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leon/anaconda3/envs/mlenv/lib/python3.11/site-packages/IPython/extensions/storemagic.py:148: UserWarning: This is now an optional IPython functionality, using autorestore/classes requires you to install the `pickleshare` library.\n",
      "  obj = db[\"autorestore/\" + arg]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-r classes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m activities \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m  k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Statement \u001b[39;00m\n\u001b[1;32m      4\u001b[0m featured_data \u001b[38;5;241m=\u001b[39m X_train\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "\n",
    "%store -r classes\n",
    "activities = [k for  k, v in classes.items()]\n",
    "# Statement \n",
    "featured_data = X_train\n",
    "labels = y_train\n",
    "\n",
    "\n",
    "# activities for each label in list activitites\n",
    "\n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
