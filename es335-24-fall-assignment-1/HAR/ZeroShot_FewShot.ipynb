{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = os.getenv('GROQ_API_TOKEN')\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: **Positive**\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "While the delivery was delayed, the user expresses positive sentiment towards the product quality and customer service. The phrase \"amazing\" clearly indicates a positive feeling about the product, and \"happy\" reinforces the positive sentiment overall.  The \"however\" acknowledges a negative aspect, but it doesn't outweigh the positive feelings expressed. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"gemma-9b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "\n",
    "answer = llm.invoke(query)\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "classes_list = list(classes.keys())\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TASK 4:\n",
    "\n",
    "> 1. Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data. Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Activity_Prediction: SITTING\n",
      "2 : Activity_Prediction: SITTING\n",
      "3 : Activity_Prediction: WALKING\n",
      "4 : Activity_Prediction: SITTING\n",
      "5 : Activity_Prediction: SITTING\n",
      "6 : Activity_Prediction: SITTING\n",
      "7 : Activity_Prediction: WALKING\n",
      "8 : Activity_Prediction: SITTING\n",
      "9 : Activity_Prediction: WALKING\n",
      "10 : Activity_Prediction: WALKING\n",
      "11 : Activity_Prediction: SITTING\n",
      "12 : Activity_Prediction: WALKING\n",
      "13 : Activity_Prediction: WALKING\n",
      "14 : Activity_Prediction: WALKING\n",
      "15 : Activity_Prediction: WALKING\n",
      "16 : Activity_Prediction: SITTING\n",
      "17 : Activity_Prediction: WALKING\n",
      "18 : Activity_Prediction: WALKING\n",
      "19 : Activity_Prediction: WALKING\n",
      "20 : Activity_Prediction: WALKING\n",
      "21 : Activity_Prediction: SITTING\n",
      "22 : Activity_Prediction: WALKING\n",
      "23 : Activity_Prediction: WALKING\n",
      "24 : Activity_Prediction: SITTING\n",
      "25 : Activity_Prediction: SITTING\n",
      "26 : Activity_Prediction: WALKING\n",
      "27 : Activity_Prediction: SITTING\n",
      "28 : Activity_Prediction: WALKING\n",
      "29 : Activity_Prediction: SITTING\n",
      "30 : Activity_Prediction: WALKING\n",
      "31 : Activity_Prediction: SITTING\n",
      "32 : Activity_Prediction: WALKING\n",
      "33 : Activity_Prediction: WALKING\n",
      "34 : Activity_Prediction: WALKING\n",
      "35 : Activity_Prediction: WALKING\n",
      "36 : Activity_Prediction: WALKING\n",
      "37 : Activity_Prediction: SITTING\n",
      "38 : Activity_Prediction: WALKING\n",
      "39 : Activity_Prediction: SITTING\n",
      "40 : Activity_Prediction: SITTING\n",
      "41 : Activity_Prediction: WALKING\n",
      "42 : Activity_Prediction: SITTING\n",
      "43 : Activity_Prediction: WALKING\n",
      "44 : Activity_Prediction: WALKING\n",
      "45 : Activity_Prediction: SITTING\n",
      "46 : Activity_Prediction: WALKING\n",
      "47 : Activity_Prediction: WALKING\n",
      "48 : Activity_Prediction: WALKING\n",
      "49 : Activity_Prediction: WALKING\n",
      "50 : Activity_Prediction: WALKING\n",
      "51 : Activity_Prediction: WALKING\n",
      "52 : Activity_Prediction: \"WALKING\"\n",
      "53 : Activity_Prediction: WALKING\n",
      "54 : Activity_Prediction: WALKING\n",
      "Number of predictions: 54\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "\n",
    "# Load and preprocess data\n",
    "X_dataset = pd.read_csv(\"X_Train_Test_data.csv\")\n",
    "y_dataset = pd.read_csv(\"Y_train_test_data.csv\")\n",
    "X_array = np.array(X_dataset).reshape(180, 500, 3)\n",
    "y_array = np.array(y_dataset[\"class_label\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, random_state=40, stratify=y_array)\n",
    "\n",
    "# Initialize LLM\n",
    "model_name = \"llama3-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "\n",
    "def predict_activity(data, llm = llm):\n",
    "    predictions = []\n",
    "    for i in range(len(data)):\n",
    "        query = f\"\"\"\n",
    "        You are a data analysis model. Predict the type of human activity from [\"WALKING\",\"WALKING_UPSTAIRS\",\"WALKING_DOWNSTAIRS\",\"SITTING\",\"STANDING\",\"LAYING\"].\n",
    "        Given: Accelerometer data (x,y,z axes) for 10 seconds at 50 Hz (500 observations).\n",
    "        Predict the activity type based on this data. Don't explain you reasoning.\n",
    "        Keep the answer precise and concise and give it in the format given below:\n",
    "        Answer format-> Activity_Prediction: \"Your Answer\".\n",
    "        Data: {data[i]}\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(query)\n",
    "        print(f\"{i+1} :\", answer.content)\n",
    "        predictions.append(answer.content)\n",
    "\n",
    "    print(f\"Number of predictions: {len(predictions)}\")\n",
    "    return predictions\n",
    "\n",
    "predictions = predict_activity(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "input = \"\"\"\n",
    "1 : Activity_Prediction: SITTING\n",
    "2 : Activity_Prediction: SITTING\n",
    "3 : Activity_Prediction: WALKING\n",
    "4 : Activity_Prediction: SITTING\n",
    "5 : Activity_Prediction: SITTING\n",
    "6 : Activity_Prediction: SITTING\n",
    "7 : Activity_Prediction: WALKING\n",
    "8 : Activity_Prediction: SITTING\n",
    "9 : Activity_Prediction: WALKING\n",
    "10 : Activity_Prediction: WALKING\n",
    "11 : Activity_Prediction: SITTING\n",
    "12 : Activity_Prediction: WALKING\n",
    "13 : Activity_Prediction: WALKING\n",
    "14 : Activity_Prediction: WALKING\n",
    "15 : Activity_Prediction: WALKING\n",
    "16 : Activity_Prediction: SITTING\n",
    "17 : Activity_Prediction: WALKING\n",
    "18 : Activity_Prediction: WALKING\n",
    "19 : Activity_Prediction: WALKING\n",
    "20 : Activity_Prediction: WALKING\n",
    "21 : Activity_Prediction: SITTING\n",
    "22 : Activity_Prediction: WALKING\n",
    "23 : Activity_Prediction: WALKING\n",
    "24 : Activity_Prediction: SITTING\n",
    "25 : Activity_Prediction: SITTING\n",
    "26 : Activity_Prediction: WALKING\n",
    "27 : Activity_Prediction: SITTING\n",
    "28 : Activity_Prediction: WALKING\n",
    "29 : Activity_Prediction: SITTING\n",
    "30 : Activity_Prediction: WALKING\n",
    "31 : Activity_Prediction: SITTING\n",
    "32 : Activity_Prediction: WALKING\n",
    "33 : Activity_Prediction: WALKING\n",
    "34 : Activity_Prediction: WALKING\n",
    "35 : Activity_Prediction: WALKING\n",
    "36 : Activity_Prediction: WALKING\n",
    "37 : Activity_Prediction: SITTING\n",
    "38 : Activity_Prediction: WALKING\n",
    "39 : Activity_Prediction: SITTING\n",
    "40 : Activity_Prediction: SITTING\n",
    "41 : Activity_Prediction: WALKING\n",
    "42 : Activity_Prediction: SITTING\n",
    "43 : Activity_Prediction: WALKING\n",
    "44 : Activity_Prediction: WALKING\n",
    "45 : Activity_Prediction: SITTING\n",
    "46 : Activity_Prediction: WALKING\n",
    "47 : Activity_Prediction: WALKING\n",
    "48 : Activity_Prediction: WALKING\n",
    "49 : Activity_Prediction: WALKING\n",
    "50 : Activity_Prediction: WALKING\n",
    "51 : Activity_Prediction: WALKING\n",
    "52 : Activity_Prediction: \"WALKING\"\n",
    "53 : Activity_Prediction: WALKING\n",
    "54 : Activity_Prediction: WALKING\n",
    "Number of predictions: 54\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_predictions = re.findall(r'\\d+\\s+:\\s+\\w+\\s*:\\s+[\"]?(\\w+)[\"]?', input)\n",
    "# len(zero_shot_predictions)\n",
    "activities = {v:k for k, v in classes.items()}\n",
    "activity_labels_0 = list(map(lambda x: activities[x], y_test))\n",
    "# len(activity_labels_0)\n",
    "accuracy = sum(a==b for a,b, in zip(zero_shot_predictions, activity_labels_0)) / len(activity_labels_0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# pattern = r'\"(.*)\"'\n",
    "\n",
    "# extracted_predictions = [re.findall(pattern, answer) for answer in predictions]\n",
    "# flattened_predictions = [pred for p1 in extracted_predictions for pred in p1]\n",
    "# # len(flattened_predictions)\n",
    "# y_train_pred = list(map(lambda x: classes.get(x), flattened_predictions))\n",
    "# y_train_1 = y_train[:50]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll analyze the data and predict the activities in the test data.\n",
      "\n",
      "After analyzing the data, I found that the activities can be broadly categorized into six classes: 'WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'LAYING', 'SITTING', and 'STANDING'.\n",
      "\n",
      "Using a classification algorithm, I predicted the activities in the test data as follows:\n",
      "\n",
      "```\n",
      "['WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'LAYING', 'SITTING', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALK\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "activities = {v:k for k, v in classes.items()}\n",
    "\n",
    "train_data = X_train\n",
    "train_labels = list(map(lambda x: activities[x], y_train))\n",
    "test_data = X_test\n",
    "test_labels = list(map(lambda x: activities[x], y_test))\n",
    "# print(train_labels, test_labels, sep=\"\\n\")\n",
    "\n",
    "query= f\"\"\"\n",
    "    * You are an data analysis model.\n",
    "    * Your task is to identify the type of activity after analysing and finding similarities of given labelled data.\n",
    "    * You will be given two sets of data (train_data, train_labels) & (test_data)\n",
    "    * test_labels are not given to you, your job will be to predict those\n",
    "    * These dataset contains data from accelerometer measuring acceleration in 3 axes: x-axis, y-axis, z-axis.\n",
    "    * Your answer is to be in the form of list, containing prediction for each activity in test_data.\n",
    "    * train_data.shape = (126, 500, 3) meaning 126 activities with 500 observations of accelerometer along 3 axes.\n",
    "    * train_labels.shape = (126,) : labels of 126 activities\n",
    "    * test_data.shape = (54, 500, 3) : 54 activity.\n",
    "    * Give your answer in form of list containing all 54 predictions of each activity\n",
    "\n",
    "    Here's the data for you:\n",
    "    train_data = {train_data}\n",
    "    train_labels = {train_labels}\n",
    "    test_data = {test_data}\n",
    "\"\"\"\n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-8b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the mistake earlier. I will re-analyze the test data and generate a new response.\n",
      "\n",
      "Based on the provided test data, I predict the following 54 activities:\n",
      "\n",
      "1. WALKING_UPSTAIRS\n",
      "2. WALKING_UPSTAIRS\n",
      "3. LAYING\n",
      "4. SITTING\n",
      "5. WALKING\n",
      "6. WALKING_DOWNSTAIRS\n",
      "7. SITTING\n",
      "8. STANDING\n",
      "9. WALKING_UPSTAIRS\n",
      "10. LAYING\n",
      "11. WALKING_UPSTAIRS\n",
      "12. SITTING\n",
      "13. WALKING_DOWNSTAIRS\n",
      "14. LAYING\n",
      "15. WALKING_UPSTAIRS\n",
      "16. WALKING_UPSTAIRS\n",
      "17. SITTING\n",
      "18. STANDING\n",
      "19. WALKING_UPSTAIRS\n",
      "20. LAYING\n",
      "21. WALKING_DOWNSTAIRS\n",
      "22. WALKING_UPSTAIRS\n",
      "23. SITTING\n",
      "24. STANDING\n",
      "25. WALKING_UPSTAIRS\n",
      "26. LAYING\n",
      "27. WALKING_UPSTAIRS\n",
      "28. SITTING\n",
      "29. WALKING_DOWNSTAIRS\n",
      "30. LAYING\n",
      "31. WALKING_UPSTAIRS\n",
      "32. WALKING_UPSTAIRS\n",
      "33. SITTING\n",
      "34. STANDING\n",
      "35. WALKING_UPSTAIRS\n",
      "36. LAYING\n",
      "37. WALKING_DOWNSTAIRS\n",
      "38. WALKING_UPSTAIRS\n",
      "39. SITTING\n",
      "40. STANDING\n",
      "41. WALKING_UPSTAIRS\n",
      "42. LAYING\n",
      "43. WALKING_UPSTAIRS\n",
      "44. SITTING\n",
      "45. WALKING_DOWNSTAIRS\n",
      "46. LAYING\n",
      "47. WALKING_UPSTAIRS\n",
      "48. WALKING_UPSTAIRS\n",
      "49. SITTING\n",
      "50. STANDING\n",
      "51. WALKING_UPSTAIRS\n",
      "52. LAYING\n",
      "53. WALKING_DOWNSTAIRS\n",
      "54. WALKING_UPSTAIRS\n",
      "\n",
      "Please note that these predictions are based on the provided test data and may not be accurate for all cases.\n"
     ]
    }
   ],
   "source": [
    "query_2 = f\"\"\"\n",
    "    Are you sure about your answer as it seems to contain way more values than what I provided in that test_data set which was 54 predictions only?\n",
    "    Your answer: {answer}\n",
    "\n",
    "    * \"Here's the data for reanalysis, do better this time\"\n",
    "    * train_data.shape = (126, 500, 3) meaning 126 activities with 500 observations of accelerometer along 3 axes.\n",
    "    * train_labels.shape = (126,) : labels of 126 activities\n",
    "    * test_data.shape = (54, 500, 3) : 54 activity.\n",
    "    * Give your answer in form of list containing all 54 predictions of each activity\n",
    "\n",
    "    Here's the data for you:\n",
    "    train_data = {train_data}\n",
    "    train_labels = {train_labels}\n",
    "    test_data = {test_data}\n",
    "    \n",
    "\"\"\"\n",
    "answer = llm.invoke(query_2)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12962962962962962\n"
     ]
    }
   ],
   "source": [
    "activity_labels = [\n",
    "    \"WALKING_UPSTAIRS\", \"WALKING_UPSTAIRS\", \"LAYING\", \"SITTING\", \"WALKING\", \n",
    "    \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"WALKING_UPSTAIRS\", \"LAYING\", \n",
    "    \"WALKING_UPSTAIRS\", \"SITTING\", \"WALKING_DOWNSTAIRS\", \"LAYING\", \"WALKING_UPSTAIRS\", \n",
    "    \"WALKING_UPSTAIRS\", \"SITTING\", \"STANDING\", \"WALKING_UPSTAIRS\", \"LAYING\", \n",
    "    \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\", \"SITTING\", \"STANDING\", \"WALKING_UPSTAIRS\", \n",
    "    \"LAYING\", \"WALKING_UPSTAIRS\", \"SITTING\", \"WALKING_DOWNSTAIRS\", \"LAYING\", \n",
    "    \"WALKING_UPSTAIRS\", \"WALKING_UPSTAIRS\", \"SITTING\", \"STANDING\", \"WALKING_UPSTAIRS\", \n",
    "    \"LAYING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\", \"SITTING\", \"STANDING\", \n",
    "    \"WALKING_UPSTAIRS\", \"LAYING\", \"WALKING_UPSTAIRS\", \"SITTING\", \"WALKING_DOWNSTAIRS\", \n",
    "    \"LAYING\", \"WALKING_UPSTAIRS\", \"WALKING_UPSTAIRS\", \"SITTING\", \"STANDING\", \n",
    "    \"WALKING_UPSTAIRS\", \"LAYING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"\n",
    "]\n",
    "\n",
    "# print(len(pred),  len(test_labels))\n",
    "\n",
    "\n",
    "accuracy = sum((a==b for a, b in zip(activity_labels, test_labels))) / len(activity_labels)\n",
    "print(accuracy)\n",
    "# So, even with few-shot not a great change in accuracy. And it's even prediciton more values than asked for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
