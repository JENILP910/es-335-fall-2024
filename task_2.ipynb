{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Generating Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy\n",
    "\n",
    "# !pip3 show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "time = 10\n",
    "offset = 100\n",
    "seed = 47\n",
    "folders = [\"LAYING\",\"SITTING\",\"STANDING\",\"WALKING\",\"WALKING_DOWNSTAIRS\",\"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "combined_dir = os.path.join(\"Combined\")\n",
    "\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X = np.concatenate((X_train,X_test))\n",
    "y = np.concatenate((y_train,y_test))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=seed,stratify=y)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Train a decision tree model using the raw accelerometer data. Report the accuracy, precision, recall and confusion matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "# y_train\n",
    "# X_test\n",
    "# y_test\n",
    "\n",
    "# print(\"X_train\", X_train)\n",
    "# print(\"Y_train\", y_train)\n",
    "# print(\"X_test\", X_test)\n",
    "# print(\"Y_test\", y_test)\n",
    "\n",
    "# X_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "X_train_reshaped = X_train.reshape(n_samples, n_timesteps * n_features)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Precision: 0.64\n",
      "Recall: 0.63\n",
      "Confusion Matrix:\n",
      "[[4 2 3 0 0 0]\n",
      " [0 3 2 0 4 0]\n",
      " [1 3 3 1 1 0]\n",
      " [0 0 0 8 1 0]\n",
      " [0 0 0 2 7 0]\n",
      " [0 0 0 0 0 9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.44      0.57         9\n",
      "           2       0.38      0.33      0.35         9\n",
      "           3       0.38      0.33      0.35         9\n",
      "           4       0.73      0.89      0.80         9\n",
      "           5       0.54      0.78      0.64         9\n",
      "           6       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.63        54\n",
      "   macro avg       0.64      0.63      0.62        54\n",
      "weighted avg       0.64      0.63      0.62        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optional: Detailed classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Train a decision tree model using the features obtained by TSFEL. Report the accuracy, precision, recall and confusion matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tsfel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfel\n",
    "\n",
    "\n",
    "sampling_frequency = 50\n",
    "\n",
    "\n",
    "# Load the default feature configuration\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "\n",
    "# Extract features for the training set\n",
    "X_train_features = []\n",
    "for i in range(X_train.shape[0]):  # Iterate over samples\n",
    "    # Extract features from the (500, 3) matrix for each sample\n",
    "    features = tsfel.time_series_features_extractor(cfg, X_train[i], fs=sampling_frequency, verbose=0)\n",
    "    X_train_features.append(features)\n",
    "\n",
    "# Convert list of DataFrames to a single DataFrame\n",
    "X_train_features = pd.concat(X_train_features).reset_index(drop=True)\n",
    "\n",
    "# Extract features for the test set\n",
    "X_test_features = []\n",
    "for i in range(X_test.shape[0]):  # Iterate over test samples\n",
    "    features = tsfel.time_series_features_extractor(cfg, X_test[i], fs=sampling_frequency, verbose=0)\n",
    "    X_test_features.append(features)\n",
    "\n",
    "# Convert list of DataFrames to a single DataFrame\n",
    "X_test_features = pd.concat(X_test_features).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 1152)\n",
      "(54, 1152)\n"
     ]
    }
   ],
   "source": [
    "# print(X_train_features.shape)\n",
    "# print(X_test_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Precision: 0.85\n",
      "Recall: 0.83\n",
      "Confusion Matrix:\n",
      "[[6 1 2 0 0 0]\n",
      " [2 7 0 0 0 0]\n",
      " [0 1 8 0 0 0]\n",
      " [0 0 0 9 0 0]\n",
      " [0 0 0 3 6 0]\n",
      " [0 0 0 0 0 9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.67      0.71         9\n",
      "           2       0.78      0.78      0.78         9\n",
      "           3       0.80      0.89      0.84         9\n",
      "           4       0.75      1.00      0.86         9\n",
      "           5       1.00      0.67      0.80         9\n",
      "           6       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.83        54\n",
      "   macro avg       0.85      0.83      0.83        54\n",
      "weighted avg       0.85      0.83      0.83        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the extracted features\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict on the test set features\n",
    "y_pred = clf.predict(X_test_features)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train a decision tree model using the features provided in the dataset. Report the accuracy, precision, recall and confusion matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.65\n",
      "Recall: 0.67\n",
      "Confusion Matrix:\n",
      "[[6 1 2 0 0 0]\n",
      " [1 3 1 1 3 0]\n",
      " [2 3 3 1 0 0]\n",
      " [0 0 0 8 1 0]\n",
      " [0 0 0 2 7 0]\n",
      " [0 0 0 0 0 9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67         9\n",
      "           2       0.43      0.33      0.38         9\n",
      "           3       0.50      0.33      0.40         9\n",
      "           4       0.67      0.89      0.76         9\n",
      "           5       0.64      0.78      0.70         9\n",
      "           6       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.67        54\n",
      "   macro avg       0.65      0.67      0.65        54\n",
      "weighted avg       0.65      0.67      0.65        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optional: Detailed classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Compare the results of the three models. Which model do you think is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Raw Accelerometer Data:\n",
    "\n",
    "Data: Time series data in its original form.\n",
    "Preprocessing: Requires reshaping or transformation.\n",
    "Pros/Cons: Retains original data but may need significant preprocessing.\n",
    "\n",
    "# 2 Features from TSFEL:\n",
    "\n",
    "Data: Extracted features representing statistical, temporal, and spectral properties.\n",
    "Preprocessing: Feature extraction is done, but feature selection might still be necessary.\n",
    "Pros/Cons: Captures time series characteristics; reduces dimensionality but may lose some temporal information.\n",
    "\n",
    "# 3 Provided Features:\n",
    "\n",
    "Data: Features are already provided and formatted.\n",
    "Preprocessing: Minimal if features are well-prepared.\n",
    "Pros/Cons: Easy to use but depends on the quality and relevance of the provided features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
